{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       [[[[ 3.1809,  3.4028,  3.3078,  ...,  3.3601,  3.2448,  2.9697],\n",
      "          [ 3.1720,  3.1282,  3.1782,  ...,  3.1889,  3.0579,  2.7655],\n",
      "          [ 3.1436,  3.1992,  3.1506,  ...,  3.0706,  3.1223,  2.7961],\n",
      "          ...,\n",
      "          [ 3.1251,  3.2096,  3.2326,  ...,  3.1659,  3.0195,  2.7531],\n",
      "          [ 3.0767,  3.0202,  3.0777,  ...,  3.1057,  3.0732,  2.8733],\n",
      "          [ 2.8401,  2.6843,  2.7070,  ...,  2.6413,  2.5772,  2.6063]],\n",
      "\n",
      "         [[-2.1899, -2.6705, -2.6629,  ..., -2.6293, -2.5751, -2.4345],\n",
      "          [-1.8450, -2.4470, -2.4169,  ..., -2.3357, -2.3819, -2.4476],\n",
      "          [-1.8554, -2.4484, -2.4139,  ..., -2.3840, -2.3607, -2.3928],\n",
      "          ...,\n",
      "          [-1.8462, -2.4711, -2.4510,  ..., -2.2677, -2.3635, -2.5292],\n",
      "          [-1.9335, -2.5423, -2.5572,  ..., -2.3625, -2.4855, -2.5208],\n",
      "          [-1.4341, -1.8804, -1.9659,  ..., -1.8571, -1.8087, -2.1149]],\n",
      "\n",
      "         [[ 2.1426,  2.0739,  2.0638,  ...,  2.0260,  2.0244,  2.2779],\n",
      "          [ 1.7365,  1.8606,  1.8281,  ...,  2.0383,  2.0107,  2.2918],\n",
      "          [ 1.6839,  1.9923,  1.9530,  ...,  2.0294,  1.9119,  2.3124],\n",
      "          ...,\n",
      "          [ 1.7281,  1.8795,  1.9381,  ...,  2.0618,  1.8526,  2.2957],\n",
      "          [ 1.6433,  1.8674,  1.8634,  ...,  1.6886,  1.7869,  2.4116],\n",
      "          [ 2.1523,  2.4529,  2.5266,  ...,  2.4677,  2.4293,  2.8040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9759,  2.0092,  2.0858,  ...,  2.0827,  2.0079,  2.2446],\n",
      "          [ 2.0267,  2.0424,  1.9985,  ...,  1.9845,  1.9813,  2.1425],\n",
      "          [ 2.0759,  2.0140,  1.9396,  ...,  2.0144,  1.9221,  2.2180],\n",
      "          ...,\n",
      "          [ 2.0072,  1.8899,  2.0604,  ...,  2.0763,  2.0128,  2.1238],\n",
      "          [ 2.0349,  1.8858,  2.1083,  ...,  2.1675,  2.0402,  2.1787],\n",
      "          [ 2.1400,  1.9063,  1.8944,  ...,  1.8289,  1.9398,  2.0082]],\n",
      "\n",
      "         [[ 1.7885,  1.6228,  1.6030,  ...,  1.6215,  1.6749,  1.5460],\n",
      "          [ 2.0707,  2.4283,  2.3454,  ...,  2.3049,  2.4453,  2.0735],\n",
      "          [ 2.0134,  2.3432,  2.3583,  ...,  2.1096,  2.3847,  2.1333],\n",
      "          ...,\n",
      "          [ 1.9721,  2.4474,  2.2688,  ...,  2.3924,  2.4327,  2.0321],\n",
      "          [ 2.0796,  2.2049,  2.2732,  ...,  2.2536,  2.3052,  2.0557],\n",
      "          [ 2.0446,  2.3021,  2.4010,  ...,  2.3129,  2.3076,  1.9994]],\n",
      "\n",
      "         [[-1.2897, -1.2770, -1.1478,  ..., -1.2336, -1.4092, -1.5820],\n",
      "          [-1.6189, -1.5709, -1.5921,  ..., -1.6878, -1.6482, -1.5591],\n",
      "          [-1.5699, -1.6298, -1.6429,  ..., -1.5625, -1.5264, -1.5496],\n",
      "          ...,\n",
      "          [-1.5661, -1.6464, -1.6784,  ..., -1.5551, -1.5101, -1.5763],\n",
      "          [-1.6460, -1.8552, -1.6773,  ..., -1.7104, -1.6629, -1.6271],\n",
      "          [-2.0598, -2.1488, -2.1168,  ..., -2.2463, -2.1910, -1.8252]]]], device='cuda:0')\n",
      "tensor([[[[ 2.3404e-01, -1.2617e+00,  4.4637e-01,  ..., -9.1024e-01,\n",
      "            9.3711e-01, -5.9653e-01],\n",
      "          [-5.1834e-01,  7.9580e-01, -3.1553e-01,  ...,  7.0441e-01,\n",
      "           -3.1443e-01,  3.4144e-02],\n",
      "          [ 3.0677e-01,  1.2295e+00, -5.2448e-01,  ...,  1.2190e-01,\n",
      "           -9.5684e-01, -1.2438e+00],\n",
      "          ...,\n",
      "          [-7.2226e-01,  8.8852e-01,  1.2532e+00,  ..., -7.8774e-01,\n",
      "           -1.9796e+00,  1.5401e+00],\n",
      "          [-7.2941e-01,  4.8571e-01,  2.5341e+00,  ...,  3.8775e-01,\n",
      "            8.6054e-01,  7.4550e-01],\n",
      "          [ 5.3724e-01,  3.1456e-01,  1.0659e+00,  ..., -8.8511e-01,\n",
      "           -4.6227e-01, -4.1345e-01]],\n",
      "\n",
      "         [[-2.9702e-01,  2.3301e+00,  1.4166e+00,  ...,  5.8576e-01,\n",
      "            8.9805e-01,  4.1130e-01],\n",
      "          [-1.8774e+00,  1.0333e+00,  3.4753e-01,  ..., -1.2371e+00,\n",
      "           -1.9197e-01,  9.8994e-01],\n",
      "          [-1.4984e+00, -1.8120e+00, -9.0525e-01,  ..., -1.4600e-02,\n",
      "           -1.0136e+00,  1.1349e-01],\n",
      "          ...,\n",
      "          [ 4.2354e-01, -1.4445e+00, -6.0690e-01,  ..., -9.6106e-02,\n",
      "            1.1366e+00,  2.0307e+00],\n",
      "          [ 5.8816e-01,  1.3065e+00,  1.1873e-01,  ...,  4.0253e-01,\n",
      "           -9.7848e-02, -6.0405e-01],\n",
      "          [ 1.5668e+00,  1.6878e-01, -7.3280e-01,  ..., -9.9341e-01,\n",
      "           -1.7752e-01, -1.0614e+00]],\n",
      "\n",
      "         [[-1.2243e+00, -7.5411e-01, -1.4010e+00,  ...,  1.5408e+00,\n",
      "            2.1057e+00, -1.2840e+00],\n",
      "          [-7.9250e-01,  9.7291e-01,  3.1767e-01,  ...,  1.6863e+00,\n",
      "            4.0355e-01, -6.1049e-01],\n",
      "          [-3.2603e-01,  8.9604e-01,  2.1299e-01,  ..., -5.6076e-01,\n",
      "           -1.0537e+00, -1.5254e+00],\n",
      "          ...,\n",
      "          [ 1.1259e+00, -6.4657e-01, -2.6991e-01,  ...,  1.1857e+00,\n",
      "            6.7404e-01, -3.6862e-01],\n",
      "          [-7.7183e-01, -1.2845e+00, -8.7027e-01,  ..., -5.3441e-02,\n",
      "            2.3197e-01, -1.9881e-01],\n",
      "          [ 6.8851e-01, -7.9389e-01,  2.2567e+00,  ..., -9.4165e-01,\n",
      "           -5.1058e-01, -8.1858e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8904e+00, -3.0129e-01,  5.4014e-01,  ...,  6.0233e-02,\n",
      "           -1.2493e+00, -1.5277e-01],\n",
      "          [ 1.9182e+00,  2.3019e+00, -4.1960e-01,  ..., -7.7482e-01,\n",
      "           -4.3482e-01,  5.0027e-01],\n",
      "          [-3.8121e-01, -5.3353e-02, -4.7181e-01,  ..., -7.8810e-01,\n",
      "           -6.0181e-01,  1.2900e+00],\n",
      "          ...,\n",
      "          [-7.0248e-01,  1.2217e+00,  9.5721e-01,  ..., -5.2269e-01,\n",
      "            2.9901e-01,  3.3168e-02],\n",
      "          [-7.1161e-01,  7.0895e-01, -1.8901e+00,  ...,  8.4635e-02,\n",
      "           -9.8280e-01, -4.2411e-01],\n",
      "          [-2.5252e-01, -1.4614e+00, -1.3981e+00,  ..., -1.1684e+00,\n",
      "            6.8712e-01,  6.5091e-01]],\n",
      "\n",
      "         [[-5.3482e-01, -2.0304e+00, -2.7506e+00,  ..., -3.9114e-01,\n",
      "           -1.5142e+00, -1.5006e-01],\n",
      "          [-1.1849e+00,  1.7005e-01, -9.5096e-01,  ..., -6.9219e-01,\n",
      "           -7.2221e-01, -4.4415e-02],\n",
      "          [-7.2200e-01, -7.9871e-01, -3.4307e-01,  ...,  1.3886e+00,\n",
      "           -1.3047e+00,  5.0024e-02],\n",
      "          ...,\n",
      "          [-5.4742e-01,  3.6731e-01,  3.2298e-01,  ...,  7.5132e-01,\n",
      "            8.3366e-01, -4.7033e-01],\n",
      "          [-4.1691e-01, -5.6675e-01, -3.1314e-01,  ...,  4.7809e-01,\n",
      "           -3.1311e-01, -4.6309e-01],\n",
      "          [-5.8792e-01,  6.8976e-01,  8.2803e-01,  ..., -1.3371e-01,\n",
      "           -1.3038e+00,  5.7810e-01]],\n",
      "\n",
      "         [[ 7.8067e-01, -2.3174e-01, -2.5284e-01,  ..., -1.3487e-01,\n",
      "           -1.8821e-01, -1.4147e+00],\n",
      "          [ 2.4501e-02,  1.6540e+00,  1.6604e+00,  ...,  5.4656e-01,\n",
      "           -4.8694e-01, -1.7733e+00],\n",
      "          [-3.9617e-01, -2.6601e+00, -3.8721e-01,  ...,  2.5980e-01,\n",
      "            2.4609e-01, -5.3005e-01],\n",
      "          ...,\n",
      "          [ 3.3849e+00, -1.7034e+00,  6.1856e-01,  ..., -1.3265e+00,\n",
      "           -2.4262e+00, -2.8565e-02],\n",
      "          [ 1.5058e-01,  8.9086e-01,  9.5724e-01,  ...,  8.9347e-01,\n",
      "            6.3458e-01, -2.2054e-01],\n",
      "          [ 8.3407e-01,  3.0053e-01,  2.1770e-01,  ...,  3.9808e-01,\n",
      "            4.6409e-01, -5.5695e-01]]]], dtype=torch.float64, device='cuda:0')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        assert hidden_channels % 2 == 0\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.bias = bias\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_features = 4\n",
    "\n",
    "        self.padding = int((kernel_size - 1) / 2)\n",
    "\n",
    "        self.Wxi = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Whi = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "        self.Wxf = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Whf = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "        self.Wxc = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=True)\n",
    "        self.Whc = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "        self.Wxo = nn.Conv2d(self.input_channels, self.hidden_channels, self.kernel_size, 1, self.padding,  bias=True)\n",
    "        self.Who = nn.Conv2d(self.hidden_channels, self.hidden_channels, self.kernel_size, 1, self.padding, bias=False)\n",
    "\n",
    "        self.Wci = None\n",
    "        self.Wcf = None\n",
    "        self.Wco = None\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        ci = torch.sigmoid(self.Wxi(x) + self.Whi(h) + c * self.Wci)\n",
    "        cf = torch.sigmoid(self.Wxf(x) + self.Whf(h) + c * self.Wcf)\n",
    "        cc = cf * c + ci * torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        co = torch.sigmoid(self.Wxo(x) + self.Who(h) + cc * self.Wco)\n",
    "        ch = co * torch.tanh(cc)\n",
    "        return ch, cc\n",
    "\n",
    "    def init_hidden(self, batch_size, hidden, shape):\n",
    "        self.Wci = Variable(torch.zeros(1, hidden, shape[0], shape[1])).cuda()\n",
    "        self.Wcf = Variable(torch.zeros(1, hidden, shape[0], shape[1])).cuda()\n",
    "        self.Wco = Variable(torch.zeros(1, hidden, shape[0], shape[1])).cuda()\n",
    "        return (Variable(torch.zeros(batch_size, hidden, shape[0], shape[1])).cuda(),\n",
    "                Variable(torch.zeros(batch_size, hidden, shape[0], shape[1])).cuda())\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    # input_channels corresponds to the first input feature map\n",
    "    # hidden state is a list of succeeding lstm layers.\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, step=1, effective_step=[1], bias=True):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.input_channels = [input_channels] + hidden_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = len(hidden_channels)\n",
    "        self.step = step\n",
    "        self.bias = bias\n",
    "        self.effective_step = effective_step\n",
    "        self._all_layers = []\n",
    "        for i in range(self.num_layers):\n",
    "            name = 'cell{}'.format(i)\n",
    "            cell = ConvLSTMCell(self.input_channels[i], self.hidden_channels[i], self.kernel_size, self.bias)\n",
    "            setattr(self, name, cell)\n",
    "            self._all_layers.append(cell)\n",
    "\n",
    "    def forward(self, input):\n",
    "        internal_state = []\n",
    "        outputs = []\n",
    "        for step in range(self.step):\n",
    "            x = input\n",
    "            for i in range(self.num_layers):\n",
    "                # all cells are initialized in the first step\n",
    "                name = 'cell{}'.format(i)\n",
    "                if step == 0:\n",
    "                    bsize, _, height, width = x.size()\n",
    "                    (h, c) = getattr(self, name).init_hidden(batch_size=bsize, hidden=self.hidden_channels[i], shape=(height, width))\n",
    "                    internal_state.append((h, c))\n",
    "\n",
    "                # do forward\n",
    "                (h, c) = internal_state[i]\n",
    "                x, new_c = getattr(self, name)(x, h, c)\n",
    "                internal_state[i] = (x, new_c)\n",
    "            # only record effective steps\n",
    "            if step in self.effective_step:\n",
    "                outputs.append(x)\n",
    "\n",
    "        return outputs, (x, new_c)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # gradient check\n",
    "    convlstm = ConvLSTM(input_channels=512, hidden_channels=[128, 64, 64, 32, 32], kernel_size=3, step=5, effective_step=[4]).cuda()\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    input = Variable(torch.randn(1, 512, 64, 32)).cuda()\n",
    "    target = Variable(torch.randn(1, 32, 64, 32)).double().cuda()\n",
    "\n",
    "    output = convlstm(input)\n",
    "    print(output[0][0])\n",
    "    print(target)\n",
    "    output = output[0][0].double()\n",
    "    res = torch.autograd.gradcheck(loss_fn, (output, target), eps=1e-6, raise_exception=True)\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
